{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a192000",
   "metadata": {},
   "source": [
    "## Question answering based on the OpenAI cookbook tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6a296",
   "metadata": {},
   "source": [
    "OpenAI has a very thorough tutorial on creating a question answering function using embeddings (https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb).\n",
    "One of the possible solutions was to follow this tutorial.\n",
    "\n",
    "The steps modified from the tutorial are: \n",
    "- Prepare the laws data\n",
    "- Create embeddings for the data\n",
    "- Create embedding for the query\n",
    "- Find most relevant text sections\n",
    "- Send query with the question and most relevant sections\n",
    "- Get query answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3e8a9",
   "metadata": {},
   "source": [
    "## Creating the embeddings file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef3a4d",
   "metadata": {},
   "source": [
    "A little section about what embeddings are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e31195",
   "metadata": {},
   "source": [
    "### Overview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bfe75",
   "metadata": {},
   "source": [
    "The original dataset contains:\n",
    "- the type or title of the law, for example VVS is \"Vabariigi Valitsuse seadus\" which translates to Government of the Republic Act\n",
    "- the paragraph number\n",
    "- the text of the paragraph\n",
    "- the link to the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d5e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from fastparquet import write\n",
    "from tables import *\n",
    "import openai  # for generating embeddings\n",
    "import pandas as pd  # for DataFrames to store article sections and embeddings\n",
    "import re  \n",
    "import tiktoken  # for counting tokens\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import faiss  # for vector database\n",
    "import scipy.spatial.distance as spatial\n",
    "import time\n",
    "from vector_database import save_index\n",
    "from vector_database import load_index\n",
    "from vector_database import strings_ranked_by_relatedness_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486c3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use embeddings you must create an .env file where the content is OPENAI_API_KEY = \"your-api-key\"\n",
    "config = dotenv_values(\".env\")[\"OPENAI_API_KEY\"]\n",
    "openai.organization = \"org-3O7bHGD9SwjHVDuUCNCGACC3\"\n",
    "openai.api_key = config\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"  # only matters insofar as it selects which tokenizer to use\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94e28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"legal_acts_estonia.csv\", names=['type', 'nr','text','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3689441b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>nr</th>\n",
       "      <th>text</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VVS</td>\n",
       "      <td>para1</td>\n",
       "      <td>§ 1.\\nVabariigi Valitsuse pädevus\\n(1) Vabarii...</td>\n",
       "      <td>https://www.riigiteataja.ee/akt/VVS#para1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type     nr                                               text  \\\n",
       "0  VVS  para1  § 1.\\nVabariigi Valitsuse pädevus\\n(1) Vabarii...   \n",
       "\n",
       "                                        link  \n",
       "0  https://www.riigiteataja.ee/akt/VVS#para1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fafb9",
   "metadata": {},
   "source": [
    "### Cleaning and splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301fcf6d",
   "metadata": {},
   "source": [
    "The tutorial suggests that long sections, which have over 1600 tokens should be split down to smaller sections. Splitting the sections allows the question query to match smaller and more  specific sections to the query and add them to the prompt, without exceeding the token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94f50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fd492",
   "metadata": {},
   "source": [
    "When splitting the paragraphs, it is important to still have the context of the paragraph, which is why the title of the paragraph is split from the text and later added to the subsections of the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeadfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"text\"].str.split(\"\\n\").str[1]\n",
    "df[\"text\"] = df[\"text\"].str.split(\"\\n\").apply(lambda x: ','.join(x[2:]))\n",
    "df[\"text\"] = df[\"text\"].str.replace('\\n','')\n",
    "#have to split up to have less than 1600 tokens\n",
    "#this will split into sections (1) ... (2) ...\n",
    "df['split_text'] = df['text'].str.split(r'\\(\\d+\\)')\n",
    "df[\"text\"] = df[\"text\"].str.replace('\\n','')\n",
    "df = df.explode(\"split_text\")\n",
    "df = df[df[\"split_text\"]!= \"\"]\n",
    "df[\"nr\"] = df[\"nr\"].str.replace('para','')\n",
    "df['token_count'] = df['split_text'].apply(num_tokens_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f01e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>nr</th>\n",
       "      <th>text</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>split_text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VVS</td>\n",
       "      <td>1</td>\n",
       "      <td>(1) Vabariigi Valitsus teostab täidesaatvat ri...</td>\n",
       "      <td>https://www.riigiteataja.ee/akt/VVS#para1</td>\n",
       "      <td>Vabariigi Valitsuse pädevus</td>\n",
       "      <td>Vabariigi Valitsus teostab täidesaatvat riigi...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type nr                                               text  \\\n",
       "0  VVS  1  (1) Vabariigi Valitsus teostab täidesaatvat ri...   \n",
       "\n",
       "                                        link                        title  \\\n",
       "0  https://www.riigiteataja.ee/akt/VVS#para1  Vabariigi Valitsuse pädevus   \n",
       "\n",
       "                                          split_text  token_count  \n",
       "0   Vabariigi Valitsus teostab täidesaatvat riigi...           39  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4e73d",
   "metadata": {},
   "source": [
    "Now, we must separate paragraphs, which have more tokens than 1600 and perform additional cleaning. This code will split the longer paragraphs by sections if there are subsections of sections, like (3.1) for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62e576a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over_length = df[df[\"token_count\"]>1600]\n",
    "#remove the long strings for now\n",
    "df = df[df[\"token_count\"]<1600]\n",
    "over_length['split_text_2'] = over_length['split_text'].str.split(r'\\(\\d+\\.\\d+\\)')\n",
    "over_length = over_length.explode(\"split_text_2\")\n",
    "over_length['token_count'] = over_length['split_text_2'].apply(num_tokens_from_string)\n",
    "#if they still have too many words, most often the paragraphs are lists of definitions, which can be split by list enumeration\n",
    "#other with a shorter length can be added back to original dataframe\n",
    "over_length_merge = over_length[over_length[\"token_count\"]<1600]\n",
    "over_length_merge = over_length_merge.drop(columns=[\"split_text\"]).rename(columns={\"split_text_2\":\"split_text\"})\n",
    "df = pd.concat([df,over_length_merge])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc66a96",
   "metadata": {},
   "source": [
    "This code is used in case there still be paragraphs with more tokens than 1600. This will split the paragraph by list enumeration elements, so 1) ..., 2) ... ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d356ecfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over_length = over_length[over_length[\"token_count\"]>1600]\n",
    "over_length[\"title_2\"] = over_length[\"split_text_2\"].str.split(r',\\d+[\\.\\d+]*\\)').str[0]\n",
    "over_length[\"split_text_3\"] = over_length[\"split_text_2\"].str.split(r',\\d+[\\.\\d+]*\\)')\n",
    "over_length = over_length.explode(\"split_text_3\")\n",
    "over_length = over_length[over_length[\"title_2\"]!=over_length[\"split_text_3\"]]\n",
    "over_length['token_count'] = over_length['split_text_3'].apply(num_tokens_from_string)\n",
    "over_length[\"title\"] = over_length[\"title\"]+ '. ' + over_length[\"title_2\"]\n",
    "over_length = over_length.drop(columns=[\"split_text\",\"split_text_2\",\"title_2\"]).rename(columns={\"split_text_3\":\"split_text\"})\n",
    "df = pd.concat([df,over_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9108e98e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True) #some laws do not have the type\n",
    "df[\"concatenated\"] = \"Seadus \"+ df[\"type\"]+\" paragrahv \"+ df[\"nr\"]+\". Pealkiri: \"+ df[\"title\"]+ \" Sisu: \"+ df[\"split_text\"]\n",
    "df[\"concatenated\"] = df[\"concatenated\"].str.replace(r'\\s+', ' ',regex=True).str.rstrip(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac2a0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seadus VVS paragrahv 1. Pealkiri: Vabariigi Valitsuse pädevus Sisu: Vabariigi Valitsus teostab täidesaatvat riigivõimu Eesti Vabariigi põhiseaduse ja seaduste alusel.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"concatenated\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a6a38",
   "metadata": {},
   "source": [
    "### Calculating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b062103",
   "metadata": {},
   "outputs": [],
   "source": [
    "laws = np.array(df[\"concatenated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "082a7fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seadus VVS paragrahv 1. Pealkiri: Vabariigi Valitsuse pädevus Sisu: Vabariigi Valitsus teostab täidesaatvat riigivõimu Eesti Vabariigi põhiseaduse ja seaduste alusel.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d870fc21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 999\n"
     ]
    }
   ],
   "source": [
    "# calculate embeddings\n",
    "\n",
    "##\n",
    "##DO NOT RUN UNLESS NEED TO CREATE NEW EMBEDDINGS (THIS CODE COSTS ABT 2 DOLLARS)\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "BATCH_SIZE = 1000  \n",
    "\n",
    "law_strings = laws.tolist()\n",
    "\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(law_strings), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = law_strings[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response[\"data\"]):\n",
    "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "result = pd.DataFrame({\"text\": law_strings, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9f77d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loading is super slow\n",
    "result.to_hdf(r'embeddedfile_all.h5', key='stage', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7e9a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = save_index(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93e52f",
   "metadata": {},
   "source": [
    "## Using the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6683ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reread = pd.read_hdf('./embeddedfile_all.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25178f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = load_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e943a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06cdc7",
   "metadata": {},
   "source": [
    "The spacial distance cosine is calculated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e53bc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seadus VTS paragrahv 20. Pealkiri: Vandetõlgi kutse andmine Sisu: Enne vandetõlgi kutsetunnistuse saamist annab isik valdkonna eest vastutava ministri ees järgmise vande:, „Tõotan oma au ja teadmiste juures olla truu Eesti Vabariigile, järgida tema põhiseadust, tegutseda vandetõlgina ausalt, väärikalt ja erapooletult ning kõigi oma võimete kohaselt.”.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seadus VVS paragrahv 6. Pealkiri: Vabariigi Valitsuse ja ministri ametisse astumine Sisu: Ametisse astuv Vabariigi Valitsuse liige märgib vandetekstile alla kirjutades sinna vande andmise kuupäeva ja kellaaja. Vanne loetakse antuks vandetekstile allakirjutamise ajast. Ametivande andmise juures viibib riigisekretär.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seadus VTS paragrahv 27. Pealkiri: Vandetõlgi kutsetegevusega seotud teabekandjad Sisu: Vandetõlgile tõlkimise käigus esitatud teabekandjate tagastamise korra vandetõlgi kutse äravõtmise ja vandetõlgi surma või raske haiguse korralkehtestab valdkonna eest vastutav ministermäärusega.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seadus VVS paragrahv 53. Pealkiri: Kantsleri pädevus Sisu: Kantsler hoiab ministeeriumi vapipitsatit.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seadus VVS paragrahv 105b11. Pealkiri: Häirekeskuse ümberkorraldamine Sisu: Ida Prefektuuri, Lääne Prefektuuri, Lõuna Prefektuuri, Põhja Prefektuuri ning Politsei- ja Piirivalveameti ülesannete järkjärgulise üleandmise tähtajad moodustatavale Häirekeskusele kehtestab siseminister käskkirjaga.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strings, relatednesses = strings_ranked_by_relatedness_vector(\"vihakuritegu\",EMBEDDING_MODEL,index,df,openai)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness_vector(query, index,df)\n",
    "    introduction = 'Use the following part of the law to answer the subsequent question. Try to find the best answer.' \\\n",
    "    'Formulate the answer including the law name and paragraph number'\\\n",
    "    'The answer should be a coherent sentence. If the answer cannot be found in the laws, write '\\\n",
    "    '\"Ei leidnud seadustest küsimusele vastust, proovige küsimus ümber sõnastada\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nSeaduse lõik:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Sa vastad Eesti seaduste andmebaasi küsimustele.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a144de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"Kuidas astub minister ametisse?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931e00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
